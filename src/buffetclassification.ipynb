{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Distribuzione delle classi:\n",
      "Classe 0: 661 stock\n",
      "Classe 1: 8 stock\n",
      "Classe 2: 8 stock\n",
      "Classe 3: 7 stock\n",
      "\n",
      "Totale stock nel dataset: 684\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carica il file CSV\n",
    "df = pd.read_csv(\"data/fundamentals_ready_multiclass.csv\")\n",
    "\n",
    "# Conta quante osservazioni ha ogni classe\n",
    "class_counts = df[\"buffett_class\"].value_counts().sort_index()\n",
    "\n",
    "# Mostra la distribuzione\n",
    "print(\"ðŸ“Š Distribuzione delle classi:\")\n",
    "for cls, count in class_counts.items():\n",
    "    print(f\"Classe {cls}: {count} stock\")\n",
    "\n",
    "# Totale\n",
    "print(f\"\\nTotale stock nel dataset: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffett_binary\n",
      "0    661\n",
      "1     23\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carica il dataset multiclass\n",
    "df = pd.read_csv(\"data/fundamentals_ready_multiclass.csv\")\n",
    "\n",
    "# Crea colonna binaria\n",
    "df[\"buffett_binary\"] = df[\"buffett_class\"].apply(lambda x: 1 if x in [1, 2, 3] else 0)\n",
    "\n",
    "# Salva nuovo file\n",
    "df.to_csv(\"data/fundamentals_ready_binary.csv\", index=False)\n",
    "\n",
    "# Mostra distribuzione binaria\n",
    "print(df[\"buffett_binary\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:31:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:31:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:31:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:31:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:31:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š K-FOLD VALIDATION RISULTATI (classe 1):\n",
      "f1        : 0.944 Â± 0.017\n",
      "precision : 0.894 Â± 0.030\n",
      "recall    : 1.000 Â± 0.000\n",
      "accuracy  : 0.970 Â± 0.010\n",
      "âœ… Modello finale salvato: models/buffett_model_balanced.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:31:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import make_scorer, classification_report, f1_score, recall_score, precision_score\n",
    "\n",
    "# === Carica dataset ===\n",
    "df = pd.read_csv(\"data/fundamentals_ready_binary.csv\")\n",
    "X = df.drop(columns=[\"Ticker\", \"buffett_class\", \"buffett_binary\"], errors=\"ignore\")\n",
    "y = df[\"buffett_binary\"]\n",
    "\n",
    "# === Bilanciamento prima del CV\n",
    "df_full = pd.concat([X, y], axis=1)\n",
    "df_0 = df_full[df_full.buffett_binary == 0]\n",
    "df_1 = df_full[df_full.buffett_binary == 1]\n",
    "\n",
    "df_0_under = resample(df_0, replace=False, n_samples=300, random_state=42)\n",
    "df_1_over = resample(df_1, replace=True, n_samples=100, random_state=42)\n",
    "\n",
    "df_bal = pd.concat([df_0_under, df_1_over])\n",
    "X_bal = df_bal.drop(columns=\"buffett_binary\")\n",
    "y_bal = df_bal[\"buffett_binary\"]\n",
    "\n",
    "# === K-Fold Stratificato\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# === Modello base\n",
    "model = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    max_depth=6,\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.2,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=1.0,\n",
    "    gamma=0\n",
    ")\n",
    "\n",
    "# === Scorer per classe 1\n",
    "scoring = {\n",
    "    \"f1\": make_scorer(f1_score, pos_label=1),\n",
    "    \"recall\": make_scorer(recall_score, pos_label=1),\n",
    "    \"precision\": make_scorer(precision_score, pos_label=1),\n",
    "    \"accuracy\": \"accuracy\"\n",
    "}\n",
    "\n",
    "# === Valutazione cross-validation\n",
    "cv_results = cross_validate(model, X_bal, y_bal, cv=skf, scoring=scoring)\n",
    "\n",
    "# === Mostra risultati\n",
    "print(\"ðŸ“Š K-FOLD VALIDATION RISULTATI (classe 1):\")\n",
    "for metric in [\"f1\", \"precision\", \"recall\", \"accuracy\"]:\n",
    "    values = cv_results[f\"test_{metric}\"]\n",
    "    print(f\"{metric:<10}: {values.mean():.3f} Â± {values.std():.3f}\")\n",
    "\n",
    "# Salva il modello completo addestrato su tutti i dati bilanciati\n",
    "model.fit(X_bal, y_bal)  # retraining su tutto\n",
    "import os, joblib\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(model, \"models/buffett_model_balanced.pkl\")\n",
    "print(\"âœ… Modello finale salvato: models/buffett_model_balanced.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”´ A â†’ Non Buffett-like. Motivo principale: mancano contributi positivi rilevanti.\n",
      "âœ… AAPL â†’ Buffett-like per: Market Cap elevato, Volume elevato, P/B elevato, Curr R basso, ROE elevato (probabilitÃ : 0.98)\n",
      "ðŸ”´ ABBV â†’ Non Buffett-like. Motivo principale: mancano contributi positivi rilevanti.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# === Carica modello e dataset ===\n",
    "model = joblib.load(\"models/buffett_model_balanced.pkl\")\n",
    "df = pd.read_csv(\"data/fundamentals_ready_binary.csv\")\n",
    "X = df.drop(columns=[\"Ticker\", \"buffett_class\", \"buffett_binary\"], errors=\"ignore\")\n",
    "tickers = df[\"Ticker\"].tolist()\n",
    "\n",
    "# === Crea explainer SHAP\n",
    "explainer = shap.Explainer(model, X)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# === Funzione per generare spiegazione testuale\n",
    "def explain_stock(index, top_n=5, threshold=0.02):\n",
    "    ticker = tickers[index]\n",
    "    pred_prob = model.predict_proba([X.iloc[index]])[0][1]\n",
    "    shap_row = shap_values[index]\n",
    "    \n",
    "    # Filtra i contributi positivi significativi\n",
    "    pos_contribs = [(X.columns[i], shap_row.values[i]) for i in range(len(shap_row.values)) if shap_row.values[i] > threshold]\n",
    "    pos_contribs = sorted(pos_contribs, key=lambda x: -x[1])[:top_n]\n",
    "\n",
    "    if pred_prob < 0.5:\n",
    "        return f\"ðŸ”´ {ticker} â†’ Non Buffett-like. Motivo principale: mancano contributi positivi rilevanti.\"\n",
    "\n",
    "    if not pos_contribs:\n",
    "        return f\"ðŸŸ¡ {ticker} â†’ Buffett-like ma nessuna feature dominante oltre soglia.\"\n",
    "\n",
    "    # Genera frase\n",
    "    components = [f\"{feat} elevato\" if X.iloc[index][feat] > X[feat].median() else f\"{feat} basso\" for feat, _ in pos_contribs]\n",
    "    frase = \", \".join(components)\n",
    "    return f\"âœ… {ticker} â†’ Buffett-like per: {frase} (probabilitÃ : {pred_prob:.2f})\"\n",
    "\n",
    "# === Esempio su 3 stock\n",
    "for i in range(3):\n",
    "    print(explain_stock(i))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
