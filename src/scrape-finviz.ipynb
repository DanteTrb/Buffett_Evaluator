{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://finviz.com/screener.ashx?v=111&f=cap_largeover,sh_avgvol_o1000&ft=4&r={}\"\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_from_page(page_number):\n",
    "    url = BASE_URL.format(page_number)\n",
    "    print(f\"üåê Requesting page {page_number} ‚Üí {url}\")\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    table = soup.find(\"table\", class_=\"table-light\")\n",
    "\n",
    "    if not table:\n",
    "        print(f\"‚ùå Nessuna tabella trovata per pagina {page_number}\")\n",
    "        return []\n",
    "\n",
    "    rows = table.find_all(\"tr\")[1:]  # skip header\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        values = [col.text.strip() for col in cols]\n",
    "        data.append(values)\n",
    "\n",
    "    print(f\"‚úÖ Pagina {page_number} ‚Üí {len(data)} righe trovate\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Requesting page 1 ‚Üí https://finviz.com/screener.ashx?v=111&f=cap_largeover,sh_avgvol_o1000&ft=4&r=1\n",
      "‚ùå Nessuna tabella trovata per pagina 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = extract_table_from_page(1)\n",
    "pd.DataFrame(data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting finvizfinance\n",
      "  Downloading finvizfinance-1.1.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from finvizfinance) (2.2.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from finvizfinance) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.11/site-packages (from finvizfinance) (4.12.2)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.11/site-packages (from finvizfinance) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->finvizfinance) (2.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->finvizfinance) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->finvizfinance) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->finvizfinance) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->finvizfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->finvizfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->finvizfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->finvizfinance) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests->finvizfinance) (2024.6.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->finvizfinance) (1.16.0)\n",
      "Downloading finvizfinance-1.1.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: finvizfinance\n",
      "Successfully installed finvizfinance-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install finvizfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV salvato con successo!#######################-] 34/35 \n"
     ]
    }
   ],
   "source": [
    "from finvizfinance.screener.overview import Overview\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Crea la cartella se non esiste\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "f = Overview()\n",
    "f.set_filter(filters_dict={\n",
    "    \"Market Cap.\": \"+Large (over $10bln)\",\n",
    "    \"Average Volume\": \"Over 1M\"\n",
    "})\n",
    "\n",
    "df = f.screener_view()\n",
    "df.to_csv(\"data/fundamentals_finviz.csv\", index=False)\n",
    "print(\"‚úÖ CSV salvato con successo!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Valuation salvato![#############################-] 34/35 \n"
     ]
    }
   ],
   "source": [
    "from finvizfinance.screener.valuation import Valuation\n",
    "\n",
    "f = Valuation()\n",
    "f.set_filter(filters_dict={\n",
    "    \"Market Cap.\": \"+Large (over $10bln)\",\n",
    "    \"Average Volume\": \"Over 1M\"\n",
    "})\n",
    "df_valuation = f.screener_view()\n",
    "df_valuation.to_csv(\"data/fundamentals_valuation.csv\", index=False)\n",
    "print(\"‚úÖ Valuation salvato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Financial salvato![#############################-] 34/35 \n"
     ]
    }
   ],
   "source": [
    "from finvizfinance.screener.financial import Financial\n",
    "\n",
    "f = Financial()\n",
    "f.set_filter(filters_dict={\n",
    "    \"Market Cap.\": \"+Large (over $10bln)\",\n",
    "    \"Average Volume\": \"Over 1M\"\n",
    "})\n",
    "df_financial = f.screener_view()\n",
    "df_financial.to_csv(\"data/fundamentals_financial.csv\", index=False)\n",
    "print(\"‚úÖ Financial salvato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Technical salvato![#############################-] 34/35 \n"
     ]
    }
   ],
   "source": [
    "from finvizfinance.screener.technical import Technical\n",
    "\n",
    "f = Technical()\n",
    "f.set_filter(filters_dict={\n",
    "    \"Market Cap.\": \"+Large (over $10bln)\",\n",
    "    \"Average Volume\": \"Over 1M\"\n",
    "})\n",
    "df_technical = f.screener_view()\n",
    "df_technical.to_csv(\"data/fundamentals_technical.csv\", index=False)\n",
    "print(\"‚úÖ Technical salvato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset unificato salvato: data/fundamentals_combined.csv\n",
      "üìä Dimensioni finali: (685, 43)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Percorso ai 4 CSV esportati\n",
    "path = \"data/\"\n",
    "file_overview = os.path.join(path, \"fundamentals_finviz.csv\")\n",
    "file_valuation = os.path.join(path, \"fundamentals_valuation.csv\")\n",
    "file_financial = os.path.join(path, \"fundamentals_financial.csv\")\n",
    "file_technical = os.path.join(path, \"fundamentals_technical.csv\")\n",
    "\n",
    "# Carica i 4 DataFrame\n",
    "df_overview = pd.read_csv(file_overview)\n",
    "df_valuation = pd.read_csv(file_valuation)\n",
    "df_financial = pd.read_csv(file_financial)\n",
    "df_technical = pd.read_csv(file_technical)\n",
    "\n",
    "# üëâ Identifica le colonne comuni (oltre 'Ticker')\n",
    "common_cols_12 = set(df_overview.columns) & set(df_valuation.columns)\n",
    "common_cols_13 = set(df_overview.columns) & set(df_financial.columns)\n",
    "common_cols_14 = set(df_overview.columns) & set(df_technical.columns)\n",
    "\n",
    "# üëâ Rimuove le colonne duplicate prima del merge, tranne 'Ticker'\n",
    "cols_to_remove_valuation = list(common_cols_12 - {\"Ticker\"})\n",
    "cols_to_remove_financial = list(common_cols_13 - {\"Ticker\"})\n",
    "cols_to_remove_technical = list(common_cols_14 - {\"Ticker\"})\n",
    "\n",
    "df_valuation = df_valuation.drop(columns=cols_to_remove_valuation)\n",
    "df_financial = df_financial.drop(columns=cols_to_remove_financial)\n",
    "df_technical = df_technical.drop(columns=cols_to_remove_technical)\n",
    "\n",
    "# ‚úÖ Merge progressivo su 'Ticker'\n",
    "df_combined = df_overview.merge(df_valuation, on=\"Ticker\", how=\"outer\")\n",
    "df_combined = df_combined.merge(df_financial, on=\"Ticker\", how=\"outer\")\n",
    "df_combined = df_combined.merge(df_technical, on=\"Ticker\", how=\"outer\")\n",
    "\n",
    "# üîé Opzionale: rimuovi colonne completamente vuote\n",
    "df_combined.dropna(axis=1, how=\"all\", inplace=True)\n",
    "\n",
    "# üíæ Salva il dataset finale\n",
    "output_file = os.path.join(path, \"fundamentals_combined.csv\")\n",
    "df_combined.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"‚úÖ Dataset unificato salvato: {output_file}\")\n",
    "print(f\"üìä Dimensioni finali: {df_combined.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset pulito salvato in: data/fundamentals_cleaned.csv\n",
      "üìä Dimensioni finali: (684, 43)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# === PARAMETRI CONFIGURABILI ===\n",
    "input_file = \"data/fundamentals_combined.csv\"\n",
    "output_file = \"data/fundamentals_cleaned.csv\"\n",
    "soglia_colonne = 30  # % di valori mancanti massima accettata per tenere una colonna\n",
    "soglia_righe = 50    # % di valori mancanti massima accettata per tenere una riga (opzionale)\n",
    "\n",
    "# === FUNZIONI UTILI ===\n",
    "\n",
    "def convert_value(x):\n",
    "    if isinstance(x, str):\n",
    "        x = x.strip().replace(\",\", \"\")\n",
    "        if x in [\"-\", \"N/A\", \"\"]:\n",
    "            return np.nan\n",
    "        if \"%\" in x:\n",
    "            try:\n",
    "                return float(x.strip(\"%\")) / 100\n",
    "            except:\n",
    "                return np.nan\n",
    "        if \"B\" in x:\n",
    "            try:\n",
    "                return float(x.replace(\"B\", \"\")) * 1e9\n",
    "            except:\n",
    "                return np.nan\n",
    "        if \"M\" in x:\n",
    "            try:\n",
    "                return float(x.replace(\"M\", \"\")) * 1e6\n",
    "            except:\n",
    "                return np.nan\n",
    "        if \"K\" in x:\n",
    "            try:\n",
    "                return float(x.replace(\"K\", \"\")) * 1e3\n",
    "            except:\n",
    "                return np.nan\n",
    "        try:\n",
    "            return float(x)\n",
    "        except:\n",
    "            return np.nan\n",
    "    return x\n",
    "\n",
    "# === STEP 1: CARICA IL FILE ===\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# === STEP 2: FILTRA COLONNE CON TROPPI NaN ===\n",
    "missing_percent = df.isnull().mean() * 100\n",
    "columns_to_keep = missing_percent[missing_percent <= soglia_colonne].index.tolist()\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# === STEP 3: CONVERTI VALORI TESTUALI IN NUMERICI\n",
    "for col in df.columns:\n",
    "    if col != \"Ticker\":\n",
    "        df[col] = df[col].apply(convert_value)\n",
    "\n",
    "# === STEP 4: RIMUOVI RIGHE CON TROPPI NaN (opzionale)\n",
    "row_missing_percent = df.isnull().mean(axis=1) * 100\n",
    "df = df[row_missing_percent <= soglia_righe]\n",
    "\n",
    "# === STEP 5: SALVA IL FILE PULITO\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"‚úÖ Dataset pulito salvato in: {output_file}\")\n",
    "print(f\"üìä Dimensioni finali: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Dataset multiclass salvato in: data/fundamentals_ready_multiclass.csv\n"
     ]
    }
   ],
   "source": [
    "# === TICKER LIST ===\n",
    "\n",
    "current_buffett = [  # top holdings attuali\n",
    "    \"AAPL\", \"KO\", \"BAC\", \"AXP\", \"CVX\", \"MCO\", \"OXY\", \"DVA\", \"KHC\"\n",
    "]\n",
    "\n",
    "past_buffett = [  # azioni possedute in passato\n",
    "    \"WFC\", \"GS\", \"VZ\", \"IBM\", \"JNJ\", \"PG\", \"TRV\", \"WMT\"\n",
    "]\n",
    "\n",
    "buffett_like = [  # azioni mai in portafoglio ma coerenti (es. brand forte, moat, ROE alto)\n",
    "    \"MSFT\", \"MA\", \"ADBE\", \"COST\", \"UNH\", \"V\", \"PEP\", \"TXN\"\n",
    "]\n",
    "\n",
    "# === CLASSIFICAZIONE MULTICLASSE ===\n",
    "\n",
    "def assign_class(ticker):\n",
    "    if ticker in current_buffett:\n",
    "        return 3\n",
    "    elif ticker in past_buffett:\n",
    "        return 2\n",
    "    elif ticker in buffett_like:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df[\"buffett_class\"] = df[\"Ticker\"].apply(assign_class)\n",
    "\n",
    "# === SALVA IL FILE ===\n",
    "df.to_csv(\"data/fundamentals_ready_multiclass.csv\", index=False)\n",
    "print(\"üéØ Dataset multiclass salvato in: data/fundamentals_ready_multiclass.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Lista delle feature utilizzabili nel modello:\n",
      "- Company\n",
      "- Sector\n",
      "- Industry\n",
      "- Country\n",
      "- Market Cap\n",
      "- P/E\n",
      "- Price\n",
      "- Change\n",
      "- Volume\n",
      "- Fwd P/E\n",
      "- PEG\n",
      "- P/S\n",
      "- P/B\n",
      "- P/C\n",
      "- P/FCF\n",
      "- EPS this Y\n",
      "- EPS next Y\n",
      "- EPS past 5Y\n",
      "- EPS next 5Y\n",
      "- Sales past 5Y\n",
      "- Dividend\n",
      "- ROA\n",
      "- ROE\n",
      "- ROI\n",
      "- Curr R\n",
      "- Quick R\n",
      "- LTDebt/Eq\n",
      "- Debt/Eq\n",
      "- Gross M\n",
      "- Oper M\n",
      "- Profit M\n",
      "- Earnings\n",
      "- Beta\n",
      "- ATR\n",
      "- SMA20\n",
      "- SMA50\n",
      "- SMA200\n",
      "- 52W High\n",
      "- 52W Low\n",
      "- RSI\n",
      "- Change from Open\n",
      "- Gap\n",
      "\n",
      "Totale: 42 feature numeriche\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carica il file CSV gi√† etichettato\n",
    "df = pd.read_csv(\"data/fundamentals_ready_multiclass.csv\")\n",
    "\n",
    "# Rimuovi eventuali colonne identificative e target\n",
    "exclude_cols = [\"Ticker\", \"buffett_class\"]\n",
    "features = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "# Mostra le feature\n",
    "print(\"üîç Lista delle feature utilizzabili nel modello:\")\n",
    "for f in features:\n",
    "    print(\"-\", f)\n",
    "\n",
    "print(f\"\\nTotale: {len(features)} feature numeriche\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
